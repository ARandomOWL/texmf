
@Article{	  Burrello2020,
  abstract	= {We develop a fast learning algorithm combining symbolic
		  dynamics and brain-inspired hyperdimensional computing for
		  both seizure onset detection and identification of
		  ictogenic (seizure generating) brain regions from
		  intracranial electroencephalography (iEEG). Methods: Our
		  algorithm first transforms iEEG time series from each
		  electrode into symbolic local binary pattern codes, from
		  which a holographic distributed representation of the brain
		  state of interest is constructed across all the electrodes
		  and over time in a hyperdimensional space. The
		  representation is used to quickly learn from few seizures,
		  detect their onset, and identify the spatial brain regions
		  that generated them. Results: We assess our algorithm on
		  our dataset that contains 99 short-time iEEG recordings
		  from 16 drug-resistant epilepsy patients being implanted
		  with 36-100 electrodes. For the majority of the patients
		  (ten out of 16), our algorithm quickly learns from one or
		  two seizures and perfectly (100{\%}) generalizes on novel
		  seizures using k-fold cross-validation. For the remaining
		  six patients, the algorithm requires three to six seizures
		  for learning. Our algorithm surpasses the state-of-the-art
		  including deep learning algorithms by achieving higher
		  specificity (94.84{\%} versus 94.77{\%}) and macroaveraging
		  accuracy (95.42{\%} versus 94.96{\%}), and 74Ã— lower
		  memory footprint, but slightly higher average latency in
		  detection (15.9 s versus 14.7 s). Moreover, the algorithm
		  can reliably identify (with a p-value {\textless} 0.01) the
		  relevant electrodes covering an ictogenic brain region at
		  two levels of granularity: cerebral hemispheres and lobes.
		  Conclusion and significance: Our algorithm provides: 1) a
		  unified method for both learning and classification tasks
		  with end-to-end binary operations; 2) one-shot learning
		  from seizure examples; 3) linear computational scalability
		  for increasing number of electrodes; and 4) generation of
		  transparent codes that enables post-translational support
		  for clinical decision making. Our source code and
		  anonymized iEEG dataset are freely available at
		  http://ieeg-swez.ethz.ch.},
  author	= {Burrello, Alessio and Schindler, Kaspar and Benini, Luca
		  and Rahimi, Abbas},
  doi		= {10.1109/TBME.2019.2919137},
  issn		= {15582531},
  journal	= {IEEE Trans. Biomed. Eng.},
  keywords	= {hyperdimensional computing,iEEG,local binary
		  patterns,localization of seizure onset zone,one-shot
		  learning,seizure detection,symbolic dynamics},
  month		= feb,
  number	= {2},
  pages		= {601--613},
  pmid		= {31144620},
  publisher	= {IEEE Computer Society},
  title		= {{Hyperdimensional Computing with Local Binary Patterns:
		  One-Shot Learning of Seizure Onset and Identification of
		  Ictogenic Brain Regions Using Short-Time iEEG Recordings}},
  volume	= {67},
  year		= {2020}
}

@Article{	  Ge2020,
  abstract	= {Hyperdimensional (HD) computing is built upon its unique
		  data type referred to as hypervectors. The dimension of
		  these hypervectors is typically in the range of tens of
		  thousands. Proposed to solve cognitive tasks, HD computing
		  aims at calculating similarity among its data. Data
		  transformation is realized by three operations, including
		  addition, multiplication and permutation. Its ultra-wide
		  data representation introduces redundancy against noise.
		  Since information is evenly distributed over every bit of
		  the hypervectors, HD computing is inherently robust.
		  Additionally, due to the nature of those three operations,
		  HD computing leads to fast learning ability, high energy
		  efficiency and acceptable accuracy in learning and
		  classification tasks. This paper introduces the background
		  of HD computing, and reviews the data representation, data
		  transformation, and similarity measurement. The
		  orthogonality in high dimensions presents opportunities for
		  flexible computing. To balance the tradeoff between
		  accuracy and efficiency, strategies include but are not
		  limited to encoding, retraining, binarization and hardware
		  acceleration. Evaluations indicate that HD computing shows
		  great potential in addressing problems using data in the
		  form of letters, signals and images. HD computing
		  especially shows significant promise to replace machine
		  learning algorithms as a light-weight classifier in the
		  field of internet of things (IoTs).},
  archiveprefix	= {arXiv},
  arxivid	= {2004.11204},
  author	= {Ge, Lulu and Parhi, Keshab K.},
  doi		= {10.1109/MCAS.2020.2988388},
  eprint	= {2004.11204},
  issn		= {15580830},
  journal	= {IEEE Circuits Syst. Mag.},
  month		= apr,
  number	= {2},
  pages		= {30--47},
  publisher	= {Institute of Electrical and Electronics Engineers Inc.},
  title		= {{Classification Using Hyperdimensional Computing: A
		  Review}},
  volume	= {20},
  year		= {2020}
}

@Article{	  Karunaratne2019,
  abstract	= {Hyperdimensional computing (HDC) is an emerging computing
		  framework that takes inspiration from attributes of
		  neuronal circuits such as hyperdimensionality, fully
		  distributed holographic representation, and
		  (pseudo)randomness. When employed for machine learning
		  tasks such as learning and classification, HDC involves
		  manipulation and comparison of large patterns within
		  memory. Moreover, a key attribute of HDC is its robustness
		  to the imperfections associated with the computational
		  substrates on which it is implemented. It is therefore
		  particularly amenable to emerging non-von Neumann paradigms
		  such as in-memory computing, where the physical attributes
		  of nanoscale memristive devices are exploited to perform
		  computation in place. Here, we present a complete in-memory
		  HDC system that achieves a near-optimum trade-off between
		  design complexity and classification accuracy based on
		  three prototypical HDC related learning tasks, namely,
		  language classification, news classification, and hand
		  gesture recognition from electromyography signals.
		  Comparable accuracies to software implementations are
		  demonstrated, experimentally, using 760,000 phase-change
		  memory devices performing analog in-memory computing.},
  archiveprefix	= {arXiv},
  arxivid	= {1906.01548},
  author	= {Karunaratne, Geethan and Gallo, Manuel Le and Cherubini,
		  Giovanni and Benini, Luca and Rahimi, Abbas and Sebastian,
		  Abu},
  eprint	= {1906.01548},
  month		= jun,
  title		= {{In-memory hyperdimensional computing}},
  url		= {http://arxiv.org/abs/1906.01548},
  year		= {2019}
}
