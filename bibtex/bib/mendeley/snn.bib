
@Article{	  Wang2019,
  abstract	= {The next wave of on-device AI will likely require
		  energy-efficient deep neural networks. Brain-inspired
		  spiking neural networks (SNN) has been identified to be a
		  promising candidate. Doing away with the need for
		  multipliers significantly reduces energy. For on-device
		  applications, besides computation, communication also
		  incurs a significant amount of energy and time. In this
		  paper, we propose Shenjing, a configurable SNN architecture
		  which fully exposes all on-chip communications to software,
		  enabling software mapping of SNN models with high accuracy
		  at low power. Unlike prior SNN architectures like
		  TrueNorth, Shenjing does not require any model modification
		  and retraining for the mapping. We show that conventional
		  artificial neural networks (ANN) such as multilayer
		  perceptron, convolutional neural networks, as well as the
		  latest residual neural networks can be mapped successfully
		  onto Shenjing, realizing ANNs with SNN's energy efficiency.
		  For the MNIST inference problem using a multilayer
		  perceptron, we were able to achieve an accuracy of 96{\%}
		  while consuming just 1.26mW using 10 Shenjing cores.},
  archiveprefix	= {arXiv},
  arxivid	= {1911.10741},
  author	= {Wang, Bo and Zhou, Jun and Wong, Weng-Fai and Peh,
		  Li-Shiuan},
  eprint	= {1911.10741},
  isbn		= {9783981926347},
  journal	= {Proc. Des. Autom. Test Eur. Conf. Exhib.},
  keywords	= {cifar10,mnist},
  mendeley-tags	= {cifar10,mnist},
  pages		= {240--245},
  title		= {{Shenjing: A low power reconfigurable neuromorphic
		  accelerator with partial-sum and spike networks-on-chip}},
  url		= {http://arxiv.org/abs/1911.10741},
  year		= {2020}
}
