
@TechReport{	  arm-trillium,
  institution	= {Arm Limited},
  keywords	= {trillium},
  title		= {{Arm AI Platform Solutions Brief}},
  url		= {www.arm.com/ai},
  year		= {2020}
}

@InProceedings{	  Banbury2020,
  abstract	= {Recent advancements in ultra-low-power machine learning
		  (TinyML) hardware promises to unlock an entirely new class
		  of smart applications. However, continued progress is
		  limited by the lack of a widely accepted benchmark for
		  these systems. Benchmarking allows us to measure and
		  thereby systematically compare, evaluate, and improve the
		  performance of systems and is therefore fundamental to a
		  field reaching maturity. In this position paper, we present
		  the current landscape of TinyML and discuss the challenges
		  and direction towards developing a fair and useful hardware
		  benchmark for TinyML workloads. Furthermore, we present our
		  three preliminary benchmarks and discuss our selection
		  methodology. Our viewpoints reflect the collective thoughts
		  of the TinyMLPerf working group that is comprised of 30
		  organizations.},
  address	= {Austin, TX, USA},
  archiveprefix	= {arXiv},
  arxivid	= {2003.04821},
  author	= {Banbury, Colby R and Reddi, Vijay Janapa and Lam, Max and
		  Fu, William and Fazel, Amin and Holleman, Jeremy and Huang,
		  Xinyuan and Hurtado, Robert and Kanter, David and
		  Lokhmotov, Anton and Patterson, David and Pau, Danilo and
		  Seo, Jae-sun and Sieracki, Jeff and Thakker, Urmish and
		  Verhelst, Marian and Yadav, Poonam},
  booktitle	= {Proc. 3rd MLSys Conf.},
  eprint	= {2003.04821},
  title		= {{Benchmarking TinyML Systems: Challenges and Direction}},
  url		= {http://arxiv.org/abs/2003.04821},
  year		= {2020}
}

@Misc{		  Capra2019,
  abstract	= {In today's world, ruled by a great amount of data and
		  mobile devices, cloud-based systems are spreading all over.
		  Such phenomenon increases the number of connected devices,
		  broadcast bandwidth, and information exchange. These
		  fine-grained interconnected systems, which enable the
		  Internet connectivity for an extremely large number of
		  facilities (far beyond the current number of devices) go by
		  the name of Internet of Things (IoT). In this scenario,
		  mobile devices have an operating time which is proportional
		  to the battery capacity, the number of operations performed
		  per cycle and the amount of exchanged data. Since the
		  transmission of data to a central cloud represents a very
		  energy-hungry operation, new computational paradigms have
		  been implemented. The computation is not completely
		  performed in the cloud, distributing the power load among
		  the nodes of the system, and data are compressed to reduce
		  the transmitted power requirements. In the edge-computing
		  paradigm, part of the computational power is moved toward
		  data collection sources, and, only after a first
		  elaboration, collected data are sent to the central cloud
		  server. Indeed, the "edge" term refers to the extremities
		  of systems represented by IoT devices. This survey paper
		  presents the hardware architectures of typical IoT devices
		  and sums up many of the low power techniques which make
		  them appealing for a large scale of applications. An
		  overview of the newest research topics is discussed,
		  besides a final example of a complete functioning system,
		  embedding all the introduced features.},
  author	= {Capra, Maurizio and Peloso, Riccardo and Masera, Guido and
		  Roch, Massimo Ruo and Martina, Maurizio},
  booktitle	= {Futur. Internet},
  doi		= {10.3390/fi11040100},
  issn		= {19995903},
  keywords	= {Edge computing,Embedded system,Internet of Things
		  (IoT),Low power,MicroController (MCU)},
  month		= apr,
  number	= {4},
  pages		= {100},
  publisher	= {MDPI AG},
  title		= {{Edge computing: A survey on the hardware requirements in
		  the Internet of Things world}},
  url		= {www.mdpi.com/journal/futureinternet},
  volume	= {11},
  year		= {2019}
}

@Article{	  Capra2020,
  abstract	= {{\textless}p{\textgreater}Deep Neural Networks (DNNs) are
		  nowadays a common practice in most of the Artificial
		  Intelligence (AI) applications. Their ability to go beyond
		  human precision has made these networks a milestone in the
		  history of AI. However, while on the one hand they present
		  cutting edge performance, on the other hand they require
		  enormous computing power. For this reason, numerous
		  optimization techniques at the hardware and software level,
		  and specialized architectures, have been developed to
		  process these models with high performance and power/energy
		  efficiency without affecting their accuracy. In the past,
		  multiple surveys have been reported to provide an overview
		  of different architectures and optimization techniques for
		  efficient execution of Deep Learning (DL) algorithms. This
		  work aims at providing an up-to-date survey, especially
		  covering the prominent works from the last 3 years of the
		  hardware architectures research for DNNs. In this paper,
		  the reader will first understand what a hardware
		  accelerator is, and what are its main components, followed
		  by the latest techniques in the field of dataflow,
		  reconfigurability, variable bit-width, and
		  sparsity.{\textless}/p{\textgreater}},
  author	= {Capra, Maurizio and Bussolino, Beatrice and Marchisio,
		  Alberto and Shafique, Muhammad and Masera, Guido and
		  Martina, Maurizio},
  doi		= {10.3390/fi12070113},
  issn		= {1999-5903},
  journal	= {Futur. Internet},
  keywords	= {AI,CNNs,DNNs,VLSI,area,artificial intelligence,computer
		  architecture,convolutional neural networks,data flow,deep
		  learning,deep neural networks,efficiency,energy,hardware
		  accelerator,latency,machine
		  learning,optimization,performance,power consumption},
  month		= jul,
  number	= {7},
  pages		= {113},
  publisher	= {Multidisciplinary Digital Publishing Institute},
  title		= {{An Updated Survey of Efficient Hardware Architectures for
		  Accelerating Deep Convolutional Neural Networks}},
  url		= {https://www.mdpi.com/1999-5903/12/7/113},
  volume	= {12},
  year		= {2020}
}

@Misc{		  Verkest,
  author	= {Verkest, Diederik},
  booktitle	= {Insid. Big Data},
  title		= {{How New Hardware Can Drastically Reduce the Power
		  Consumption of Artificial Intelligence}},
  url		= {https://insidebigdata.com/2020/07/27/how-new-hardware-can-drastically-reduce-the-power-consumption-of-artificial-intelligence/},
  urldate	= {2020-08-15}
}
